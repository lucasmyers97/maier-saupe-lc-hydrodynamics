
@article{schimming_computational_2020,
	title = {Computational molecular field theory for nematic liquid crystals},
	volume = {101},
	issn = {2470-0045, 2470-0053},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.101.032702},
	doi = {10.1103/PhysRevE.101.032702},
	language = {en},
	number = {3},
	urldate = {2021-11-19},
	journal = {Physical Review E},
	author = {Schimming, Cody D. and Viñals, Jorge},
	month = mar,
	year = {2020},
	pages = {032702},
	file = {Schimming and Viñals - 2020 - Computational molecular field theory for nematic l.pdf:/home/lucas/Zotero/storage/YKR759VW/Schimming and Viñals - 2020 - Computational molecular field theory for nematic l.pdf:application/pdf},
}

@article{qian_generalized_1998,
	title = {Generalized hydrodynamic equations for nematic liquid crystals},
	volume = {58},
	issn = {1063-651X, 1095-3787},
	url = {https://link.aps.org/doi/10.1103/PhysRevE.58.7475},
	doi = {10.1103/PhysRevE.58.7475},
	language = {en},
	number = {6},
	urldate = {2021-12-21},
	journal = {Physical Review E},
	author = {Qian, Tiezheng and Sheng, Ping},
	month = dec,
	year = {1998},
	pages = {7475--7485},
	file = {Qian and Sheng - 1998 - Generalized hydrodynamic equations for nematic liq.pdf:/home/lucas/Zotero/storage/GSBG7CGZ/Qian and Sheng - 1998 - Generalized hydrodynamic equations for nematic liq.pdf:application/pdf},
}

@article{bangerth_algorithms_2011,
	title = {Algorithms and data structures for massively parallel generic adaptive finite element codes},
	volume = {38},
	issn = {0098-3500, 1557-7295},
	url = {https://dl.acm.org/doi/10.1145/2049673.2049678},
	doi = {10.1145/2049673.2049678},
	abstract = {Today's largest supercomputers have 100,000s of processor cores and offer the potential to solve partial differential equations discretized by billions of unknowns. However, the complexity of scaling to such large machines and problem sizes has so far prevented the emergence of generic software libraries that support such computations, although these would lower the threshold of entry and enable many more applications to benefit from large-scale computing.
            We are concerned with providing this functionality for mesh-adaptive finite element computations. We assume the existence of an “oracle” that implements the generation and modification of an adaptive mesh distributed across many processors, and that responds to queries about its structure. Based on querying the oracle, we develop scalable algorithms and data structures for generic finite element methods. Specifically, we consider the parallel distribution of mesh data, global enumeration of degrees of freedom, constraints, and postprocessing. Our algorithms remove the bottlenecks that typically limit large-scale adaptive finite element analyses.
            We demonstrate scalability of complete finite element workflows on up to 16,384 processors. An implementation of the proposed algorithms, based on the open source software p4est as mesh oracle, is provided under an open source license through the widely used deal.II finite element software library.},
	language = {en},
	number = {2},
	urldate = {2022-02-24},
	journal = {ACM Transactions on Mathematical Software},
	author = {Bangerth, Wolfgang and Burstedde, Carsten and Heister, Timo and Kronbichler, Martin},
	month = dec,
	year = {2011},
	pages = {1--28},
	file = {Bangerth et al. - 2011 - Algorithms and data structures for massively paral.pdf:/home/lucas/Zotero/storage/MT7XVWA2/Bangerth et al. - 2011 - Algorithms and data structures for massively paral.pdf:application/pdf},
}

@book{selinger_introduction_2016,
	address = {Cham},
	series = {Soft and {Biological} {Matter}},
	title = {Introduction to the {Theory} of {Soft} {Matter}: {From} {Ideal} {Gases} to {Liquid} {Crystals}},
	isbn = {978-3-319-21053-7 978-3-319-21054-4},
	shorttitle = {Introduction to the {Theory} of {Soft} {Matter}},
	url = {http://link.springer.com/10.1007/978-3-319-21054-4},
	language = {en},
	urldate = {2022-03-08},
	publisher = {Springer International Publishing},
	author = {Selinger, Jonathan V.},
	year = {2016},
	doi = {10.1007/978-3-319-21054-4},
	file = {Selinger - 2016 - Introduction to the Theory of Soft Matter From Id.pdf:/home/lucas/Zotero/storage/4E6YPZ6Q/Selinger - 2016 - Introduction to the Theory of Soft Matter From Id.pdf:application/pdf},
}

@article{arndt_dealii_2021,
	title = {The deal.{II} library, {Version} 9.3},
	volume = {29},
	issn = {1570-2820, 1569-3953},
	url = {https://www.degruyter.com/document/doi/10.1515/jnma-2021-0081/html},
	doi = {10.1515/jnma-2021-0081},
	abstract = {This paper provides an overview of the new features of the finite element library deal.II, version 9.3.},
	language = {en},
	number = {3},
	urldate = {2022-03-08},
	journal = {Journal of Numerical Mathematics},
	author = {Arndt, Daniel and Bangerth, Wolfgang and Blais, Bruno and Fehling, Marc and Gassmöller, Rene and Heister, Timo and Heltai, Luca and Köcher, Uwe and Kronbichler, Martin and Maier, Matthias and Munch, Peter and Pelteret, Jean-Paul and Proell, Sebastian and Simon, Konrad and Turcksin, Bruno and Wells, David and Zhang, Jiaqi},
	month = sep,
	year = {2021},
	pages = {171--186},
	file = {Arndt et al. - 2021 - The deal.II library, Version 9.3.pdf:/home/lucas/Zotero/storage/ARU4ZEIG/Arndt et al. - 2021 - The deal.II library, Version 9.3.pdf:application/pdf},
}

@article{burstedde_p4est_2011,
	title = {p4est : {Scalable} {Algorithms} for {Parallel} {Adaptive} {Mesh} {Refinement} on {Forests} of {Octrees}},
	volume = {33},
	issn = {1064-8275, 1095-7197},
	shorttitle = {p4est},
	url = {http://epubs.siam.org/doi/10.1137/100791634},
	doi = {10.1137/100791634},
	abstract = {We present scalable algorithms for parallel adaptive mesh reﬁnement and coarsening (AMR), partitioning, and 2:1 balancing on computational domains composed of multiple connected two-dimensional quadtrees or three-dimensional octrees, referred to as a forest of octrees. By distributing the union of octants from all octrees in parallel, we combine the high scalability proven previously for adaptive single-octree algorithms with the geometric ﬂexibility that can be achieved by arbitrarily connected hexahedral macromeshes, in which each macroelement is the root of an adapted octree. A key concept of our approach is an encoding scheme of the interoctree connectivity that permits arbitrary relative orientations between octrees. Based on this encoding we develop interoctree transformations of octants. These form the basis for high-level parallel octree algorithms, which are designed to interact with an application code such as a numerical solver for partial diﬀerential equations. We have implemented and tested these algorithms in the p4est software library. We demonstrate the parallel scalability of p4est on its own and in combination with two geophysics codes. Using p4est we generate and adapt multioctree meshes with up to 5.13 × 1011 octants on as many as 220,320 CPU cores and execute the 2:1 balance algorithm in less than 10 seconds per million octants per process.},
	language = {en},
	number = {3},
	urldate = {2022-03-08},
	journal = {SIAM Journal on Scientific Computing},
	author = {Burstedde, Carsten and Wilcox, Lucas C. and Ghattas, Omar},
	month = jan,
	year = {2011},
	pages = {1103--1133},
	file = {Burstedde et al. - 2011 - p4est  Scalable Algorithms for Parallel Adaptive .pdf:/home/lucas/Zotero/storage/L9ACK2AV/Burstedde et al. - 2011 - p4est  Scalable Algorithms for Parallel Adaptive .pdf:application/pdf},
}

@misc{balay_petsc_2021,
	title = {{PETSc} {Web} page},
	url = {https://petsc.org/},
	author = {Balay, Satish and Abhyankar, Shrirang and Adams, Mark F. and Benson, Steven and Brown, Jed and Brune, Peter and Buschelman, Kris and Constantinescu, Emil M. and Dalcin, Lisandro and Dener, Alp and Eijkhout, Victor and Gropp, William D. and Hapla, Václav and Isaac, Tobin and Jolivet, Pierre and Karpeev, Dmitry and Kaushik, Dinesh and Knepley, Matthew G. and Kong, Fande and Kruger, Scott and May, Dave A. and McInnes, Lois Curfman and Mills, Richard Tran and Mitchell, Lawrence and Munson, Todd and Roman, Jose E. and Rupp, Karl and Sanan, Patrick and Sarich, Jason and Smith, Barry F. and Zampini, Stefano and Zhang, Hong and Zhang, Hong and Zhang, Junchao},
	year = {2021},
}

@techreport{balay_petsctao_2021,
	title = {{PETSc}/{TAO} {Users} {Manual}},
	number = {ANL-21/39 - Revision 3.16},
	institution = {Argonne National Laboratory},
	author = {Balay, Satish and Abhyankar, Shrirang and Adams, Mark F. and Benson, Steven and Brown, Jed and Brune, Peter and Buschelman, Kris and Constantinescu, Emil and Dalcin, Lisandro and Dener, Alp and Eijkhout, Victor and Gropp, William D. and Hapla, Václav and Isaac, Tobin and Jolivet, Pierre and Karpeev, Dmitry and Kaushik, Dinesh and Knepley, Matthew G. and Kong, Fande and Kruger, Scott and May, Dave A. and McInnes, Lois Curfman and Mills, Richard Tran and Mitchell, Lawrence and Munson, Todd and Roman, Jose E. and Rupp, Karl and Sanan, Patrick and Sarich, Jason and Smith, Barry F. and Zampini, Stefano and Zhang, Hong and Zhang, Hong and Zhang, Junchao},
	year = {2021},
}

@inproceedings{balay_efficient_1997,
	title = {Efficient {Management} of {Parallelism} in {Object} {Oriented} {Numerical} {Software} {Libraries}},
	booktitle = {Modern {Software} {Tools} in {Scientific} {Computing}},
	publisher = {Birkhäuser Press},
	author = {Balay, Satish and Gropp, William D. and McInnes, Lois Curfman and Smith, Barry F.},
	editor = {Arge, E. and Bruaset, A. M. and Langtangen, H. P.},
	year = {1997},
	pages = {163--202},
}

@article{falgout_design_2004,
	title = {The {Design} and {Implementation} of hypre, a {Library} of {Parallel} {High} {Performance} {Preconditioners}},
	volume = {51},
	url = {https://www.osti.gov/biblio/875356},
	journal = {Lecture Notes in Computational Science and Engineering},
	author = {Falgout, R D and Jones, J E and Yang, U M},
	month = jul,
	year = {2004},
}

@article{henson_boomeramg_2002,
	title = {{BoomerAMG}: a {Parallel} {Algebraic} {Multigrid} {Solver} and {Preconditioner}},
	volume = {41},
	number = {5},
	journal = {Applied Numerical Mathematics},
	author = {Henson, V. E. and Yang, U. M.},
	year = {2002},
	pages = {155--177},
	annote = {Also available as LLNL technical report UCRL-JC-141495},
}

@misc{burkhardt_lebedev_quadrature,
  title = {Quadrature Rules for the Unit Sphere},
  howpublished = {\url{https://people.math.sc.edu/Burkardt/cpp_src/sphere_lebedev_rule/sphere_lebedev_rule.html}},
  note = {Accessed: 2022-03-08}
}

@software{Myers_maier-saupe-lc-hydrodynamics_2022,
author = {Myers, Lucas},
month = {3},
title = {{maier-saupe-lc-hydrodynamics}},
url = {https://github.com/lucasmyers97/maier-saupe-lc-hydrodynamics},
version = {1.0.0},
year = {2022}
note = {Available at \url{https://github.com/lucasmyers97/maier-saupe-lc-hydrodynamics}, version 1.0.0}
}

@Inbook{Brezina2011,
author="Brezina, Marian
and Hu, Jonathan
and Tuminaro, Ray",
editor="Padua, David",
title="Algebraic Multigrid",
bookTitle="Encyclopedia of Parallel Computing",
year="2011",
publisher="Springer US",
address="Boston, MA",
pages="23--33",
isbn="978-0-387-09766-4",
doi="10.1007/978-0-387-09766-4_498",
url="https://doi.org/10.1007/978-0-387-09766-4_498"
}

@inbook{doi:10.1137/1.9781611971057.ch4,
author = { J. W. Ruge  and  K. Stüben },
title = {4. Algebraic Multigrid},
booktitle = {Multigrid Methods},
chapter = {},
pages = {73-130},
doi = {10.1137/1.9781611971057.ch4},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611971057.ch4},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611971057.ch4},
    abstract = { 4.1. Introduction. The focus in the application of standard multigrid methods is on the continuous problem to be solved. With the geometry of the problem known, the user discretizes the corresponding operators on a sequence of increasingly finer grids, each grid generally being a uniform refinement of the previous one, with transfer operators between the grids. The coarsest grid is sufficiently coarse to make the cost of solving the (residual) problem there negligible, while the finest is chosen to provide some desired degree of accuracy. The solution process, which involves relaxation, transfer of residuals from fine to coarse grids, and interpolation of corrections from coarse to fine levels, is a very efficient solver for the problem on the finest grid, provided the above “multigrid components” are properly chosen. Roughly, the efficiency of proper multigrid methods is due to the fact that error only slightly affected by relaxation ( smooth error) can be easily approximated on a coarser grid by solving the residual equation there, where it is cheaper to compute. This error approximation is interpolated to the fine grid and used to correct the solution. Generally, uniform coarsening and linear interpolation are used, so the key to constructing an efficient multigrid algorithm is to pick the relaxation process that quickly reduces error not in the range of interpolation. The algebraic multigrid (AMG) approach is developed to solve matrix equations using the principles of usual multigrid methods. In contrast to “geometric” multigrid methods, the relaxation used in AMG is fixed. The coarsening process (picking the coarse “grid” and defining interpolation) is performed automatically in a way that ensures the range of interpolation approximates those errors not efficiently reduced by relaxation. From a theoretical point of view, the process is best understood in the context of symmetric M-matrices, although, in practice, its use is not restricted to such cases. The underlying idea of the coarsening process is to exploit the fact that the form of the error after relaxation can be approximately expressed using the equations themselves, so that the coarse grid can be chosen and interpolation defined if the equations are used directly. This makes AMG attractive as a “black box” solver. In addition, AMG can be used for many kinds of problems, described below, where the application of standard multigrid methods is difficult or impossible. }
}